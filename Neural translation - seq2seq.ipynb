{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural translation - seq2seq\n",
    "## French questions to english questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difficulties:**\n",
    "\n",
    "1. Output of arbitrary length\n",
    "1. Order of tokens in the input and the output is not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "http://www.statmt.org/wmt15/translation-task.html\n",
    "\n",
    "Obtained by web crawling millions of sites and using simple heuristics such as replacing *en* with *fr* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate/')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'giga-fren.release2.fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fn = PATH/f'{filename}.en'\n",
    "fr_fn = PATH/f'{filename}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a full translation model takes a long time. In this example we therefore focus only on questions that start with *What*, *Where*, *Wh...* etc. and end with a *?*.\n",
    "\n",
    "Compiling makes the regular expressions faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_enquest = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_frquest = re.compile('^([^?.!]+\\?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ((re_enquest.search(enquest), re_frquest.search(frquest)) for enquest, frquest in zip(open(en_fn, encoding='utf-8'), open(fr_fn, encoding='utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(<_sre.SRE_Match object; span=(0, 15), match='What is light ?'>, <_sre.SRE_Match object; span=(0, 25), match='Qu’est-ce que la lumière?'>)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, <_sre.SRE_Match object; span=(0, 72), match=\"Astronomes Introduction Vidéo d'introduction Qu'e>)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(<_sre.SRE_Match object; span=(0, 11), match='Who are we?'>, <_sre.SRE_Match object; span=(0, 15), match='Où sommes-nous?'>)\n",
      "(<_sre.SRE_Match object; span=(0, 23), match='Where did we come from?'>, <_sre.SRE_Match object; span=(0, 17), match=\"D'où venons-nous?\">)\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(lines):\n",
    "    print(l)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [(e.group(), f.group()) for e, f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(questions, (PATH/'fr-en-questions.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pickle.load((PATH/'fr-en-questions.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       " ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "  'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?'),\n",
       " ('What is the major aboriginal group on Vancouver Island?',\n",
       "  'Quel est le groupe autochtone principal sur l’île de Vancouver?')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52328"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_questions, fr_questions = zip(*questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tokenizer` is a fastai wrapper around *spacy* that uses multiple processors for speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_questions), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'would', 'we', 'do', 'without', 'it', '?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['que', 'ferions', '-', 'nous', 'sans', 'elle', '?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_tok[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average length of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.345895123069868"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(q) for q in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.26809738572084"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(q) for q in fr_tok])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discard questions that are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(q) < 30 for q in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2idxs(tok, pre):\n",
    "    freq = Counter(t for q in tok for t in q)\n",
    "    itos = [s for s, c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')  # beginning of sequence token\n",
    "    itos.insert(1, '_pad_')  # padding token\n",
    "    itos.insert(2, '_eos_')  # end of sequence token\n",
    "    itos.insert(3, '_unk_')  # unknown token\n",
    "    stoi = collections.defaultdict(lambda: 3, {t:i for i,t in enumerate(itos)})  # if string not found, set to '_unk_'\n",
    "    indcs = np.array([([stoi[t] for t in q] + [2]) for q in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_indcs.npy', indcs)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos_pkl', 'wb'))\n",
    "    return indcs, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indcs, en_itos, fr_stoi = toks2idxs(en_tok, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_indcs, fr_itos, fr_stoi = toks2idxs(fr_tok, 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indcs(pre):\n",
    "    indcs = np.load(TMP_PATH/f'{pre}_indcs.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos_pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {t:i for i,t in enumerate(itos)})\n",
    "    return indcs, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indcs, en_itos, en_stoi = load_indcs('en')\n",
    "fr_indcs, fr_itos, fr_stoi = load_indcs('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what would we do without it ? _eos_'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([en_itos[i] for i in en_indcs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'que ferions - nous sans elle ? _eos_'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([fr_itos[i] for i in fr_indcs[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'word_vectors'/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vecs = ft.load_model(str(PATH/'word_vectors'/'wiki.fr.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vec_dict = {w: ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vec_dict, open(PATH/f'wiki.{lang}.pkl', 'wb'))\n",
    "    return vec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vec_dict = get_vecs('en', en_vecs)\n",
    "fr_vec_dict = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vec_dict = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "en_vec_dict = pickle.load(open(PATH/'wiki.en.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_words = en_vecs.get_words(include_freq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_word_dict = {k:v for k,v in zip(*ft_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])  # sorted by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by',\n",
       " 'as',\n",
       " 'for',\n",
       " 's',\n",
       " 'on',\n",
       " 'was',\n",
       " 'is',\n",
       " 'a',\n",
       " 'to',\n",
       " '(',\n",
       " ')',\n",
       " \"'\",\n",
       " 'and',\n",
       " 'in',\n",
       " '-',\n",
       " 'of',\n",
       " '</s>',\n",
       " 'the',\n",
       " '.',\n",
       " ',']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519370"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality of the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_en_vec = len(en_vec_dict['and'])\n",
    "dim_fr_vec = len(fr_vec_dict['and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec, dim_fr_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean and stdv of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = np.stack(list(en_vec_dict.values()))\n",
    "# keys are words, values are the vectors of size 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2519370, 300)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs.mean(), en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`en_indcs` are the numericalized questions.\n",
    "\n",
    "**Percentile:**\n",
    "*Ist beispielsweise eine Stichprobe von Schuhgrößen gegeben, so ist das empirische 0,35-Quantil diejenige Schuhgröße s , so dass 35 % der Schuhgrößen in der Stichprobe kleiner als s  sind und 65 % größer als s sind.* [source](https://de.wikipedia.org/wiki/Empirisches_Quantil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_len_99 = int(np.percentile([len(o) for o in en_indcs], 99))\n",
    "fr_len_97 = int(np.percentile([len(o) for o in fr_indcs], 97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 33)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_len_99, fr_len_97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncate the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indcs_trunc = np.array([q[:en_len_99] for q in en_indcs])\n",
    "fr_indcs_trunc = np.array([q[:fr_len_97] for q in fr_indcs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` object needs a `__getitem__` and a `__len__` method. This example is actually very general and can be used for any arrays..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "    def __getitem__(self, idx):\n",
    "        return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "??A()  # returns a np.array if len == 1 else returns a list of np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_keep = np.random.rand(len(en_indcs_trunc)) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_trn, fr_trn = en_indcs_trunc[trn_keep], fr_indcs_trunc[trn_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_val, fr_val = en_indcs_trunc[~trn_keep], fr_indcs_trunc[~trn_keep]  # tilde negates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45218, 5039)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_trn), len(en_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets for french to english translation. Swap arguments to create a english to french model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(fr_trn, en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val, en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'que ferions - nous sans elle ? _eos_'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([fr_itos[o] for o in fr_trn[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what would we do without it ? _eos_'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([en_itos[o] for o in en_trn[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything still looking as expected :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to fully utilize the GPUs capabilities, we train in batches. The length of a minibatch tensor is set by the sequence length of the longest question in that batch. The other questions are padded. To save time and memory, we want to avoid very long and very short questions in one batch because that would mean lot's of padding. For the validation set we simply sort the questions. For training we use the `SortishSampler` which groups *longer* questions together and *shorter* questions together while preserving some randomness.\n",
    "\n",
    "For language models it's better to pad before the start of the sequence because we need the final hidden state to predict the next token or for classification...\n",
    "\n",
    "For sequence to sequence models it is better to pad after the end of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sampler = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_sampler = SortSampler(en_val, key=lambda x:len(en_val[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both samplers simply return indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = next(iter(trn_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why do birds live near the ocean ? _eos_'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([en_itos[o] for o in en_trn[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pourquoi certains oiseaux vivent - ils à proximité de la mer ? _eos_'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([fr_itos[o] for o in fr_trn[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, pad_idx=1, pre_pad=False, sampler=trn_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader(val_ds, int(1.5*bs), transpose=True, transpose_y=True, num_workers=1, pad_idx=1, pre_pad=False, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the ModelData object combines the training and validation dataloaders and a path to story temp stuff. When you have a ModelData object you can create a learner and then call `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at an example batch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 18), (25, 8), (21, 9)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(x), len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en ce qui concerne l’ adhésion des 10 nouveaux états membres , quelle est la proposition correcte ? _eos_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_\n",
      "which of the following is correct as regards the accession of the 10 new member states ? _eos_\n",
      "\n",
      "quels stimulateurs de croissance sont autorisés au canada ? _eos_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_\n",
      "which products are approved in canada ? _eos_\n",
      "\n",
      "qui a -t -on atteint avec le programme ? _eos_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_\n",
      "who has been reached by the program ? _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in its:\n",
    "    print(' '.join([fr_itos[o] for o in x[:,0]]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,0]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hid, n_layers = 256, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(wordvecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    weights = emb.weight.data\n",
    "    not_found = []\n",
    "    for idx, word in enumerate(itos):\n",
    "        try:\n",
    "            weights[idx] = torch.from_numpy(wordvecs[word] * 3)  # wordvecs is a dict\n",
    "            # wordvecs have stdv of ~0.3, embedding of 1, the found and not found ones should have same stdv\n",
    "        except:\n",
    "            not_found.append(word)\n",
    "    print(len(not_found), not_found[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, emb_sz_enc, vecs_dec, itos_dec, emb_sz_dec, nh, out_seqlen, nl=2):\n",
    "        super().__init__()\n",
    "        self.nh, self.nl, self.out_seqlen = nh, nl, out_seqlen\n",
    "        \n",
    "        # Encoder\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, emb_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.rnn_enc = nn.GRU(emb_sz_enc, nh, num_layers=nl, dropout=0.25)  # sz 300 in, sz 256 out\n",
    "        self.outp_enc = nn.Linear(nh, emb_sz_dec, bias=False)               # sz 256 in, sz 300 out\n",
    "        \n",
    "        # Decoder\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, emb_sz_dec)\n",
    "        self.rnn_dec = nn.GRU(emb_sz_dec, emb_sz_dec, num_layers=nl, dropout=0.1)  # square to enable weight tying\n",
    "        self.out_drop = nn.Dropout(0.35)                                           # sz 300 in, 300 out\n",
    "        self.out = nn.Linear(emb_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data                            # weight tying! not transposed?\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        seqlen, bs = inp.size()\n",
    "        \n",
    "        # Encoder\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_outp, h = self.rnn_enc(emb, h)\n",
    "        # pdb.set_trace()\n",
    "        h = self.outp_enc(h)  # h[1] is same as enc_outp[-1]!\n",
    "\n",
    "        # Decoder\n",
    "        dec_inp = V(torch.zeros(bs).long())  # 0 is 'beginning of seq' token\n",
    "        res = []\n",
    "        for i in range(self.out_seqlen):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)  # adds unit axis at beginning so that rnn 'loops' once\n",
    "            outp, h = self.rnn_dec(emb, h)  # 'loops' once\n",
    "            outp = self.out(self.out_drop(outp[0]))  # 0 because 'loops' once, predictions for words\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])  # [1] to get argmax\n",
    "            if (dec_inp == 1).all(): break    # if all sentences in the minibatch have _pad_ as input, break\n",
    "        return torch.stack(res)\n",
    "        \n",
    "    def initHidden(self, bs):\n",
    "        return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoder:** `outp`is the same as `h[1]` (has two layers)\n",
    "```\n",
    "p outp.shape\n",
    "torch.Size([1, 187, 300])\n",
    "\n",
    "p h.shape\n",
    "torch.Size([2, 187, 300])\n",
    "```\n",
    "\n",
    "**Encoder:**\n",
    "```\n",
    "p enc_outp.shape\n",
    "torch.Size([33, 187, 256])\n",
    "\n",
    "p h.shape\n",
    "torch.Size([2, 187, 256])\n",
    "```\n",
    "\n",
    "`enc_outp[-1]` and `h[1]` are the same\n",
    "\n",
    "(187 is bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Seq2SeqLoss(pred, target):\n",
    "    seqlen, bs = target.size()\n",
    "    seqlen_pred, bs_pred, n_probs = pred.size()\n",
    "    \n",
    "    # we need to pad if target seqlen is larger than prediction seqlen\n",
    "    if seqlen > seqlen_pred:\n",
    "        pred = F.pad(pred, (0,0,0,0,0,seqlen-seqlen_pred))\n",
    "    \n",
    "    # but we only compare until the seqlen of the target\n",
    "    pred = pred[:seqlen]\n",
    "    \n",
    "    # cross_entropy can't handle rank 3 tensors currently, we need to flatten\n",
    "    return F.cross_entropy(pred.view(-1, n_probs), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))  # like bind in c++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_fr_vec, dim_en_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(fr_vec_dict, fr_itos, dim_fr_vec, en_vec_dict, en_itos, dim_en_vec, n_hid, en_len_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's kind of understandable that these tokens where not found in the word vectors we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(modeldata, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)  # SingleModel makes the model one layer group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit = Seq2SeqLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ee66c85b9c498d89b575fa9b128563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 241/362 [00:23<00:12, 10.06it/s, loss=37.1]"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d96c9b3d854c0083895c6b5f4827b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 52/362 [00:05<00:30, 10.00it/s, loss=8.32]\n",
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.44016    5.701974  \n",
      "    1      4.310874   4.549533                              \n",
      "    2      3.890306   4.157954                              \n",
      "    3      3.719702   4.019643                              \n",
      "    4      3.322341   3.865383                              \n",
      "    5      3.221692   3.795207                              \n",
      "    6      3.220406   3.697457                              \n",
      "    7      3.244708   3.7222                                \n",
      "    8      2.893455   3.646579                              \n",
      "    9      2.846069   3.616925                              \n",
      "    10     2.784473   3.573879                              \n",
      "    11     2.667841   3.572502                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.572502047460784]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, n_cycle=1, cycle_len=12, use_clr=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(itertools.islice(iter(val_dl), 25, None))\n",
    "probs = learn.model(V(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 187, 17573])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = to_np(probs.max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu' est ce que l ' t_up ipv ? _eos_\n",
      "what is t_up api ? _eos_\n",
      "what is the t_up ? _eos_\n",
      "\n",
      "qu' entend - on par autres méthodes de déclaration ? _eos_\n",
      "what is alternate reporting ? _eos_\n",
      "what are other other ? ? _eos_\n",
      "\n",
      "que montrent - elles ? _eos_\n",
      "what does it show ? _eos_\n",
      "what do they do ? _eos_\n",
      "\n",
      "qui est en conflit ? _eos_\n",
      "who is in conflict ? _eos_\n",
      "who is conflict ? _eos_\n",
      "\n",
      "pourquoi encourager davantage la recherche ? _eos_\n",
      "why encourage more research ? _eos_\n",
      "why encourage more promote research ? _eos_\n",
      "\n",
      "qui sont les vulnérables ? _eos_\n",
      "who are the vulnerable ? _eos_\n",
      "who are vulnerable ? ?\n",
      "\n",
      "pourquoi encourager davantage la recherché ? _eos_\n",
      "why encourage more research ? _eos_\n",
      "why encourage we more ? _eos_ _eos_\n",
      "\n",
      "qu’ est -ce que des données identifiables ? _eos_\n",
      "what is identifiable data ? _eos_\n",
      "what is the ? ? _eos_\n",
      "\n",
      "pourquoi était - il l' adversaire de sir john ? _eos_\n",
      "why were they opponents ? _eos_\n",
      "why was he shoemaker ’s ? ? _eos_\n",
      "\n",
      "qu' est -ce que l' admissibilité partagée ? _eos_\n",
      "what is shared eligibility ? _eos_\n",
      "what is the - eligibility ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = 110\n",
    "for i in range(start, start + 10):\n",
    "    print(' '.join([fr_itos[o] for o in x[:, i] if o != 1]))  # Input\n",
    "    print(' '.join([en_itos[o] for o in y[:, i] if o != 1]))  # Target\n",
    "    print(' '.join([en_itos[o] for o in preds[:, i] if o != 1]))  # Prediction\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
