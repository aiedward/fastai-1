{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural translation - seq2seq\n",
    "## French questions to english questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difficulties:**\n",
    "\n",
    "1. Output of arbitrary length\n",
    "1. Order of tokens in the input and the output is not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "http://www.statmt.org/wmt15/translation-task.html\n",
    "\n",
    "Obtained by web crawling millions of sites and using simple heuristics such as replacing *en* with *fr* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate/')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'giga-fren.release2.fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fn = PATH/f'{filename}.en'\n",
    "fr_fn = PATH/f'{filename}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a full translation model takes a long time. In this example we therefore focus only on questions that start with *What*, *Where*, *Wh...* etc. and end with a *?*.\n",
    "\n",
    "Compiling makes the regular expressions faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_enquest = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_frquest = re.compile('^([^?.!]+\\?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ((re_enquest.search(enquest), re_frquest.search(frquest)) for enquest, frquest in zip(open(en_fn, encoding='utf-8'), open(fr_fn, encoding='utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(<_sre.SRE_Match object; span=(0, 15), match='What is light ?'>, <_sre.SRE_Match object; span=(0, 25), match='Qu’est-ce que la lumière?'>)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, <_sre.SRE_Match object; span=(0, 72), match=\"Astronomes Introduction Vidéo d'introduction Qu'e>)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(None, None)\n",
      "(<_sre.SRE_Match object; span=(0, 11), match='Who are we?'>, <_sre.SRE_Match object; span=(0, 15), match='Où sommes-nous?'>)\n",
      "(<_sre.SRE_Match object; span=(0, 23), match='Where did we come from?'>, <_sre.SRE_Match object; span=(0, 17), match=\"D'où venons-nous?\">)\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(lines):\n",
    "    print(l)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [(e.group(), f.group()) for e, f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(questions, (PATH/'fr-en-questions.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pickle.load((PATH/'fr-en-questions.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       " ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "  'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?'),\n",
       " ('What is the major aboriginal group on Vancouver Island?',\n",
       "  'Quel est le groupe autochtone principal sur l’île de Vancouver?')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52328"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_questions, fr_questions = zip(*questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tokenizer` is a fastai wrapper around *spacy* that uses multiple processors for speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_questions), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'would', 'we', 'do', 'without', 'it', '?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['que', 'ferions', '-', 'nous', 'sans', 'elle', '?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_tok[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average length of the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.345895123069868"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(q) for q in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.26809738572084"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(q) for q in fr_tok])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discard questions that are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(q) < 30 for q in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2idxs(tok, pre):\n",
    "    freq = Counter(t for q in tok for t in q)\n",
    "    itos = [s for s, c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')  # beginning of sequence token\n",
    "    itos.insert(1, '_pad_')  # padding token\n",
    "    itos.insert(2, '_eos_')  # end of sequence token\n",
    "    itos.insert(3, '_unk_')  # unknown token\n",
    "    stoi = collections.defaultdict(lambda: 3, {t:i for i,t in enumerate(itos)})  # if string not found, set to '_unk_'\n",
    "    indcs = np.array([([stoi[t] for t in q] + [2]) for q in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_indcs.npy', indcs)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos_pkl', 'wb'))\n",
    "    return indcs, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indcs, en_itos, fr_stoi = toks2idxs(en_tok, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_indcs, fr_itos, fr_stoi = toks2idxs(fr_tok, 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indcs(pre):\n",
    "    indcs = np.load(TMP_PATH/f'{pre}_indcs.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos_pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {t:i for i,t in enumerate(itos)})\n",
    "    return indcs, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indcs, en_itos, en_stoi = load_indcs('en')\n",
    "fr_indcs, fr_itos, fr_stoi = load_indcs('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what would we do without it ? _eos_'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([en_itos[i] for i in en_indcs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'que ferions - nous sans elle ? _eos_'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([fr_itos[i] for i in fr_indcs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
